openai:
  creds_key_file: "openai_creds/openai_api_key.txt"
  model_name: "gpt-3.5-turbo-0125"
local:
  port: 1
  model_path: "mistralai/Mixtral-8x7B-Instruct-v0.1" 
query:
  max_request_time: 100
  num_samples: 1
  temperature: 0.0
  sleep_time: 10
  max_tokens: 500
methods:
  ### Data contamination methods
  - name: "gpt-2"
    type: "data" # choices: ["data", "model"], whether it's a data-contamination method or model-contamination method
    help: "Method in GPT-2 paper -> string matching (8-gram)"

  - name: "gpt-3"
    type: "data"
    help: "Method in GPT-3 paper -> string matching (13-gram)"

  - name: "palm"
    type: "data"
    help: "Method in PaLM paper -> string matching (8-grams)"

  - name: "gpt-4"
    type: "data"
    help: "Method in GPT-4 technical report -> string matching (50-chars)"

  - name: "platypus"
    type: "data"
    help: "Method in Platypus paper -> cosine similarity between Sentence Transformers embeddings"

  ### Model contamination methods
  - name: "guided-prompting"
    type: "model"
    help: "Method in TIME TRAVEL IN LLMS: TRACING DATA CONTAMINATION IN LARGE LANGUAGE MODELS"

  - name: "sharded-likelihood"
    type: "model"
    help: "Method in PROVING TEST SET CONTAMINATION IN BLACK BOX LANGUAGE MODELS"

  - name: "min-prob"
    type: "model"
    help: "Detecting Pretraining Data from Large Language Models."
  
